# üß™ Complete Testing Guide for FF_Agent Enhancement
**All 4 Phases: Prompt Engineering + RAG + Feedback + Fine-tuning**

## Quick Start Testing

### 1Ô∏è‚É£ Start the Enhanced API
```bash
# Terminal 1: Start the API with all enhancements
source venv/bin/activate
python3 api_with_feedback.py
```

The API should show:
```
üöÄ Starting FF_Agent with Complete Enhancement Stack
==================================================
‚úÖ Phase 1: Prompt Engineering - Active
‚úÖ Phase 2: RAG Enhancement - Active
‚úÖ Phase 3: Feedback Loop - Active
==================================================
Starting server at http://localhost:8000
```

### 2Ô∏è‚É£ Run the Complete System Test
```bash
# Terminal 2: Run comprehensive test
source venv/bin/activate
python3 test_complete_system.py
```

## Detailed Testing Instructions

### Test Phase 1: Prompt Engineering
```bash
# Test entity detection and classification
python3 test_prompt_improvements.py
```

Expected Results:
- ‚úÖ Entity detection: 93% accuracy
- ‚úÖ Firebase routing: "List all staff" ‚Üí FIREBASE_QUERY
- ‚úÖ Project code detection: "LAW-001" ‚Üí Lawley project
- ‚úÖ Telecom terms: "PON utilization" ‚Üí includes formula

### Test Phase 2: RAG Enhancement
```bash
# Test document ingestion and retrieval
python3 test_rag_enhancement.py
```

Expected Results:
- ‚úÖ Document ingestion: 45 files processed
- ‚úÖ Entity extraction: Telecom terms detected
- ‚úÖ Chunking: Large documents split correctly
- ‚úÖ Search simulation: Finds relevant documents

### Test Phase 3: Feedback Loop
```bash
# Test feedback collection and learning
python3 feedback_system.py
```

Expected Results:
- ‚úÖ Feedback collected for queries
- ‚úÖ Performance metrics tracked
- ‚úÖ Learning patterns identified
- ‚úÖ Training data exported

### Test Phase 4: Fine-tuning
```bash
# Test fine-tuning data preparation
python3 finetuning_system.py
```

Expected Results:
- ‚úÖ Training data prepared (50+ examples)
- ‚úÖ Data validated and exported
- ‚úÖ Cost estimation calculated
- ‚úÖ Evaluation framework working

## Interactive Testing

### Test via API Endpoints

#### 1. Check System Status
```bash
curl http://localhost:8000/
```

Should return:
```json
{
  "status": "operational",
  "phases_active": {
    "phase1_prompt_engineering": true,
    "phase2_rag": true,
    "phase3_feedback_loop": true
  }
}
```

#### 2. Test a Query with All Enhancements
```bash
curl -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{
    "question": "List all staff",
    "use_rag": true,
    "use_feedback": true
  }'
```

Expected Response:
```json
{
  "success": true,
  "query_id": "q_xxxxx",
  "sql": "FIREBASE_QUERY: staff",
  "entities_detected": {
    "personnel": ["staff"]
  },
  "query_classification": {
    "type": "personnel",
    "databases": ["firebase"]
  },
  "similar_queries": [...],
  "recommendations": {...}
}
```

#### 3. Submit Feedback
```bash
curl -X POST http://localhost:8000/feedback/q_xxxxx \
  -H "Content-Type: application/json" \
  -d '{
    "feedback": "positive",
    "comment": "Correctly routed to Firebase"
  }'
```

#### 4. Check Performance Metrics
```bash
curl http://localhost:8000/performance
```

#### 5. Get Performance Report
```bash
curl http://localhost:8000/performance/report
```

#### 6. Export Training Data
```bash
curl -X POST http://localhost:8000/learn/export
```

## Test Queries to Try

### Phase 1 Tests (Entity Detection)
1. "List all staff" ‚Üí Should route to Firebase
2. "Show drops in LAW-001" ‚Üí Should detect Lawley project
3. "Calculate PON utilization" ‚Üí Should include /32 formula
4. "What's the splice loss?" ‚Üí Should detect measurement

### Phase 2 Tests (RAG Context)
1. "How to calculate PON utilization?" ‚Üí Should find relevant docs
2. "Show similar queries about drops" ‚Üí Should retrieve examples
3. "What tables are available?" ‚Üí Should use schema context

### Phase 3 Tests (Feedback Learning)
1. Submit positive feedback ‚Üí Should improve success rate
2. Submit correction ‚Üí Should learn from mistake
3. Check metrics ‚Üí Should show learning progress

### Phase 4 Tests (Fine-tuning Ready)
1. Export training data ‚Üí Should generate JSONL files
2. Check data quality ‚Üí Should have valid examples
3. Estimate cost ‚Üí Should calculate training requirements

## Complete System Test Script

```bash
#!/bin/bash
# complete_test.sh

echo "üß™ Testing Complete FF_Agent Enhancement System"
echo "=============================================="

# Check if API is running
echo "1. Checking API status..."
curl -s http://localhost:8000/ | python3 -m json.tool

# Test Phase 1: Entity Detection
echo -e "\n2. Testing Phase 1 - Entity Detection..."
curl -s -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "List all staff"}' | python3 -m json.tool

# Test Phase 2: RAG
echo -e "\n3. Testing Phase 2 - RAG Context..."
curl -s -X POST http://localhost:8000/query \
  -H "Content-Type: application/json" \
  -d '{"question": "Calculate PON utilization", "use_rag": true}' | python3 -m json.tool

# Test Phase 3: Feedback
echo -e "\n4. Testing Phase 3 - Feedback..."
curl -s http://localhost:8000/performance | python3 -m json.tool

# Test Phase 4: Fine-tuning
echo -e "\n5. Testing Phase 4 - Export Training Data..."
curl -s -X POST http://localhost:8000/learn/export | python3 -m json.tool

echo -e "\n‚úÖ All tests complete!"
```

## Verification Checklist

### Phase 1 ‚úì
- [ ] Entity detection working (93% accuracy)
- [ ] Database routing correct (Firebase vs PostgreSQL)
- [ ] Project codes detected (LAW, IVY, MAM, MOH)
- [ ] Telecom terms recognized

### Phase 2 ‚úì
- [ ] Documents ingested successfully
- [ ] Similar queries retrieved
- [ ] Context added to prompts
- [ ] Search working

### Phase 3 ‚úì
- [ ] Feedback collected
- [ ] Metrics tracked
- [ ] Learning patterns identified
- [ ] Performance report generated

### Phase 4 ‚úì
- [ ] Training data prepared
- [ ] Data validated
- [ ] Export working
- [ ] Ready for fine-tuning

## Troubleshooting

### API Won't Start
```bash
# Check dependencies
pip install -r requirements.txt

# Check environment variables
cat .env
# Should have:
# NEON_DATABASE_URL=...
# GOOGLE_AI_STUDIO_API_KEY=...
```

### Import Errors
```bash
# Make sure all files exist
ls *.py | grep -E "(prompt_|document_|feedback_|finetuning_)"
```

### Database Connection Issues
```bash
# Test without database
python3 -c "from prompt_improvements import EnhancedPromptGenerator; print('‚úÖ Imports working')"
```

## Expected Success Metrics

After running all tests:
- **Total files created**: 20+
- **Entity detection rate**: 93%
- **Document ingestion**: 100%
- **Feedback collection**: Working
- **Training data**: 50+ examples ready
- **All 4 phases**: Active and integrated

## Summary

The complete system should demonstrate:
1. **Smart query understanding** (Phase 1)
2. **Context retrieval** (Phase 2)
3. **Continuous learning** (Phase 3)
4. **Ready for specialization** (Phase 4)

All working together to create a self-improving AI system!